Multi-agent apps with Semantic Kernel or LangChain & Azure Cosmos DB
1 Hr 41 Min Remaining 
Multi-agent apps with Semantic Kernel or LangChain & Azure Cosmos DB
Your Lab Environment
Welcome to our multi-agent workshop for a retail banking scenario. This hands-on-lab comes in two flavors, C# using Semantic Kernel Agents and Python using LangGraph.

To begin, log into the virtual machine using the following credentials: Pa$$w0rd

Note: Text formatted as an example represents type text. Clicking on this text will automatically insert it to prevent any typing errors.

Next, using the drop-down, select which hands-on-lab you would like to complete, Semantic Kernel Agents in C# or LangGraph in Python.

If you are taking this as an on-demand lab, open the PDF on the desktop and review the content before starting your lab. Scheduled lab attendees will watch presentation.


csharp

Build a Multi-Agent App using Semantic Kernel Agents
Welcome to our Multi-Agent Workshop. The source code for this is available at https://github.com/AzureCosmosDB/banking-multi-agent-workshop. Feel free to save this URL so you can clone and run the comleted sample and retake this HOL yourself.

Learning Path
The workshop follows a progressive learning path with the following Modules

Module 0: Configure local lab resources
Module 1: Creating Your First Agent
Module 2: Connecting Agents to Memory
Module 3: Agent Specialization
Module 4: Multi-Agent Orchestration
Module 00 - Configure local lab resources
Introduction
In this Module, you'll configure the lab resources then start the application to ensure everything has been properly configured.

Open a browser locally on the VM and navigate to https://portal.azure.com
Login using the credentials below
User name User1-51583669@LODSPRODMCA.onmicrosoft.com
Password Gp0Ae4@!Dg
In the Search box at the top of the Azure Portal, type in resource group. Open the Resource groups blade
Open the resource group that starts with: rg-agenthol-.
If the resource group does not appear wait a few moments then refresh.
When the new resource group appears, expand the Overview tab and click deployments. essentials-tab-deployments
If all resources have been deployed successfully, you are ready to begin the lab. Your screen should look like this. deployments
Leave this browser open to the Azure Portal.
Proceed to Running the App
Running the App
Start the Backend App
Open VS Code from the desktop.
This should open this folder by default, "C:\Users\LabUser\multi-agent-hol\". If not, navigate to and open this folder.
From the menu, select Terminal, New Terminal, then open a new PowerShell terminal.
Navigate to csharp\src\MultiAgentCopilot.
shell
cd csharp\src\MultiAgentCopilot
Type dotnet run to start the multi-agent service.
You will notice some warnings when the app starts. You can ignore these.
When you see Semantic Kernel service initialized the app has started.
Leave the app running.
Start the Frontend App
Next we will start the frontend application. We will leave this running for the duration of the lab.
Within VS Code, open a new terminal.
Navigate to the frontend folder.
shell
cd frontend
Copy and run the following:
shell
npm install
npm start
If prompted, Allow so the Node.js Javascript Runtime can access this app over the network.
Open your browser and navigate to http://localhost:4200/.
Start a Conversation
In the Login dialog, select a user and company and click, Login.
Start a new conversation.
Send the message:
text
Hello, how are you?
You should see something like the output below.

Test output

Stop the Application
Return to VS Code.
Select the backend terminal, press Ctrl + C to stop the backend application.
Note: Leave the front-end application running for the duration of the lab.

Next Steps
Proceed to Module 1: Creating Your First Agent

Module 01 - Creating Your First Agent
Introduction
In this Module, you'll implement your first agent as part of a multi-agent banking system implemented using Semantic Kernel Agent Framework. You will get an introduction to Semantic Kernel and their plug-in integration with OpenAI for generating completions.

Learning Objectives and Activities
Learn the basics for Semantic Kernel Agent Framework
Learn how to integrate agent frameworks to Azure OpenAI
Build a simple chat agent
Module Exercises
Activity 1: Instantiate Agent Framework
Activity 2: Create a Simple Agent
Activity 3: Test your Work
Activity 1: Instantiate Semantic Kernel Agent Framework
In this hands-on exercise, you will learn how to initialize an agent framework and integrate it with a Large Language Model(LLM).

The Semantic Kernel Agent Framework is a platform within Microsoft's Semantic Kernel ecosystem designed to facilitate the creation and orchestration of AI agents. It enables developers to incorporate agentic patterns into applications. Agents built using this framework can collaborate, manage multiple concurrent conversations, and integrate human input, making it suitable for complex, multi-agent workflows.

There are a few key components and concepts necessary to build multi-agent apps using this framework.

AgentChat - In the Semantic Kernel framework, AgentChat is an abstract class designed to facilitate interactions among multiple agents, even if they are of different types. This design allows, for example, a ChatCompletionAgent and an OpenAIAssistantAgent which are concrete implementations to collaborate within the same conversation. The AgentChat class defines entry points for initiating collaboration between agents, supporting scenarios where multiple responses or a single agent response are required. As an abstract class, AgentChat can be subclassed to support custom scenarios.

Functions - Functions in Semantic Kernel are discrete units of work that can be executed within the AI application. They come in two primary forms:

Native - These are standard methods that perform specific tasks, such as accessing a database, calling an external API, or processing data. To define a native function, you create a method in your codebase and annotate it with attributes that describe its purpose and parameters. This metadata allows the Semantic Kernel to understand and utilize the function appropriately.
Semantic - These functions are defined using natural language prompts and are designed to interact with LLMs. They guide the model to generate responses or perform tasks based on the provided prompt. Semantic functions are typically stored as text files, (for example, Prompty) containing the prompt and are loaded into the application at runtime. They can include variables and expressions to make the prompts dynamic and context-aware.
Plugins - A plugin in Semantic Kernel is a collection of related functions-both native and semantic-that are grouped to provide a cohesive set of capabilities. Plugins serve as modular components that can be easily integrated into AI applications to extend their functionality.​ A plugin is typically implemented as a class containing multiple functions. Each function within the plugin is annotated with descriptive metadata, enabling the Semantic Kernel to understand its purpose and how to invoke it. Plugins encapsulate functionality that can be reused across different parts of an application or even across multiple applications. They promote modularity and maintainability by organizing related functions into a single, coherent unit. To use a plugin, it is imported into the Semantic Kernel, which then makes its functions available for invocation. This integration allows AI applications to dynamically utilize the plugin's capabilities as needed.

Connectors - ​In the Semantic Kernel framework, Connectors serve as essential bridges that facilitate seamless integration between the kernel and various external services and AI models. These connectors enable developers to incorporate diverse AI functionalities-such as text generation, chat completion, embeddings, Vector Search, and more-into their applications without delving into the complexities of each AI provider's API. There are two types of connectors we will use in this workshop, AI Connectors and Vector Store Connectors.

AI Connectors - AI Connectors provide a uniform interface to interact with multiple AI services, such as Chat Completion and Embedding Generation, allowing developers to switch between different AI providers effortlessly. This flexibility is particularly beneficial for experimenting with various models to determine the best fit for specific use cases.
Vector Store Connectors - Beyond direct AI service integrations, Semantic Kernel provides connectors for various vector databases, including Azure Cosmos DB, facilitating tasks like semantic search and retrieval-augmented generation (RAG).
Let's dive into the starter solution for our workshop and get started completing the implementation for our multi-agent application.

Implement the SemanticKernelService
We are going to define two functions as part of our multi-agent application.

GetResponse() will be the entry point called by the front end to interact with the multi-agent service. Everything happens behind this function.
Summarize() will be used to summarize the conversations users are having with the agent service.
In VS Code, use the explorer on the left-hand side of the IDE to open the csharp\src\MultiAgentCopilot\Services folder.
Within the \Services folder navigate to SemanticKernelService.cs.
Search for //TO DO: Update SemanticKernelService constructor and paste the code below.
Note: To paste code, place your cursor exactly where you want it in the code, including any tabs or spaces, then click the T in the lab guide. This will paste the code directly into your app. You may need to tab or format the code a little after pasting.

csharp
    builder.Services.AddSingleton<ILoggerFactory>(loggerFactory);

        DefaultAzureCredential credential;
        if (string.IsNullOrEmpty(_skSettings.AzureOpenAISettings.UserAssignedIdentityClientID))
        {
            credential = new DefaultAzureCredential();
        }
        else
        {
            credential = new DefaultAzureCredential(new DefaultAzureCredentialOptions
            {
                ManagedIdentityClientId = _skSettings.AzureOpenAISettings.UserAssignedIdentityClientID
            });
        }

        builder.AddAzureOpenAIChatCompletion(
           _skSettings.AzureOpenAISettings.CompletionsDeployment,
           _skSettings.AzureOpenAISettings.Endpoint,
           credential);
Activity 2: Create a Simple Agent
Let's create a very simple agent for our workshop that is powered by an LLM. This agent will simply greet users and translate their requests into French. We will also implement a summarize function that renames the current chat session based upon the current topic from the user.

Search for //TO DO: Add GetResponse function and paste the code below.
csharp
public async Task<Tuple<List<Message>, List<DebugLog>>> GetResponse(Message userMessage, List<Message> messageHistory, BankingDataService bankService, string tenantId, string userId)
    {
        try
        {
            ChatCompletionAgent agent = new ChatCompletionAgent
            {
                Name = "BasicAgent",
                Instructions = "Greet the user and translate the request into French",
                Kernel = _semanticKernel.Clone()
            };


            // Create an null AgentThread 
            AgentThread agentThread = null;

            _promptDebugProperties = new List<LogProperty>();

            List<Message> completionMessages = new();
            List<DebugLog> completionMessagesLogs = new();


            await foreach (ChatMessageContent response in agent.InvokeAsync(userMessage.Text, agentThread))
            {
                string messageId = Guid.NewGuid().ToString();
                completionMessages.Add(new Message(userMessage.TenantId, userMessage.UserId, userMessage.SessionId, response.AuthorName ?? string.Empty, response.Role.ToString(), response.Content ?? string.Empty, messageId));
            }
            return new Tuple<List<Message>, List<DebugLog>>(completionMessages, completionMessagesLogs);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error when getting response: {ErrorMessage}", ex.ToString());
            return new Tuple<List<Message>, List<DebugLog>>(new List<Message>(), new List<DebugLog>());
        }
    }
Search for //TO DO: Add Summarize function and paste the code below.
csharp
public async Task<string> Summarize(string sessionId, string userPrompt)
    {
        try
        {
            // Use an AI function to summarize the text in 2 words
            var summarizeFunction = _semanticKernel.CreateFunctionFromPrompt(
                "Summarize the following text into exactly two words:\n\n{{$input}}",
                executionSettings: new OpenAIPromptExecutionSettings { MaxTokens = 10 }
            );

            // Invoke the function
            var summary = await _semanticKernel.InvokeAsync(summarizeFunction, new() { ["input"] = userPrompt });

            return summary.GetValue<string>() ?? "No summary generated";
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error when getting response: {ErrorMessage}", ex.ToString());
            return string.Empty;
        }
    }
Update ChatService
Remain in the /Services folder
Navigate to ChatService.cs.
Replace the code for GetChatCompletionAsync() method with code below.
csharp
    public async Task<List<Message>> GetChatCompletionAsync(string tenantId, string userId, string? sessionId, string userPrompt)
    {
        try
        {
            ArgumentNullException.ThrowIfNull(sessionId);

            // Add both prompt and completion to cache, then persist in Cosmos DB
            var userMessage = new Message(tenantId, userId, sessionId, "User", "User", userPrompt);

            // Generate the completion to return to the user
            var result = await _skService.GetResponse(userMessage, new List<Message>(), _bankService, tenantId, userId);

            return result.Item1;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"Error getting completion in session {sessionId} for user prompt [{userPrompt}].");
            return new List<Message> { new Message(tenantId, userId, sessionId!, "Error", "Error", $"Error getting completion in session {sessionId} for user prompt [{userPrompt}].") };
        }
    }
Replace the code for SummarizeChatSessionNameAsync method with code below.

csharp
public async Task<string> SummarizeChatSessionNameAsync(string tenantId, string userId,string? sessionId, string prompt)
    {
        try
        {
            ArgumentNullException.ThrowIfNull(sessionId);

            var summary = await _skService.Summarize(sessionId, prompt);

            var session = await RenameChatSessionAsync(tenantId, userId,sessionId, summary);

            return session.Name;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"Error getting a summary in session {sessionId} for user prompt [{prompt}].");
            return $"Error getting a summary in session {sessionId} for user prompt [{prompt}].";
        }

    }
Activity 3: Test your Work
With the activities in this module complete, it is time to test your work. The agent should respond and greet you then translate your request into French.

Start the Backend
Return to the open terminal for the backend app in VS Code and type dotnet run
Start a Chat Session
Return to the still running frontend application in your browser.
Send the message:
text
Hello, how are you?
You should see something like the output below.

Test output in French

Stop the Application
Return to VS Code.
Select the backend terminal, press Ctrl + C to stop the backend application.
Validation Checklist
Your implementation is successful if:

Your app compiles with no errors.
Your agent successfully processes user input and generates and appropriate response.
Module Solution
The following sections include the completed code for this Module. Copy and paste these into your project if you run into issues and cannot resolve.

Completed code for \Services\ChatService.cs
Completed code for \Services\SemanticKernelService.cs
Next Steps
Proceed to Module 2: Connecting Agents to Memory

Module 02 - Connecting Agents to Memory
Introduction
In this Module you'll connect your agent to Azure Cosmos DB to provide memory for chat history and state management for your agents to provide durability and context-awareness in your agent interactions.

Learning Objectives and Activities
Learn the basics for Azure Cosmos DB for storing state and chat history
Learn how to integrate agent frameworks to Azure Cosmos DB
Test connectivity to Azure Cosmos DB
Module Exercises
Activity 1: Create a Simple Banking Agent
Activity 2: Connecting Agent Frameworks to Azure Cosmos DB
Activity 3: Test your Work
Activity 1: Create a Simple Banking Agent
In this hands-on exercise, we will evolve the agent that translated responses into French into an agent that is intended for the banking scenario we are building here. We will also take the first step to learning about prompts.

Add Agent Factory
Agents are autonomous systems that use LLMs to process inputs, make decisions, and generate responses based on predefined goals. They can integrate with external tools, retrieve information, and adapt dynamically to different tasks. We are next going to implement a AgentFactory class that enables the creation of agents for various scenarios. It uses the GetAgentPrompts to define the agent prompts.

In VS Code, navigate to the /Factories folder.
Next, open AgentFactory.cs.
Within the internal class definition for AgentFactory paste the code below:
csharp
        private string GetAgentName()
        {

            return "FrontDeskAgent";
        }


        private string GetAgentPrompts()
        {

            string prompt = "You are a front desk agent in a bank. Respond to the user queries professionally. Provide professional and helpful responses to user queries.Use your knowledge of banking services and procedures to address user queries accurately.";
            return prompt;
        }


        public ChatCompletionAgent BuildAgent(Kernel kernel, ILoggerFactory loggerFactory, BankingDataService bankService, string tenantId, string userId)
        {
            ChatCompletionAgent agent = new ChatCompletionAgent
            {
                Name = GetAgentName(),
                Instructions = $"""{GetAgentPrompts()}""",
                Kernel = kernel.Clone()
            };

            return agent;
        }
We now have an agent that executes instructions provided as prompts.

Next lets add some memory so that the agent can remember the previous messages and doesn't loose context of the chat session.

Activity 2: Connecting Agent Frameworks to Azure Cosmos DB
In this activity, you will learn how to initialize Azure Cosmos DB and integrate with an agent framework to provide persistent memory for chat history and state management.

Update GetResponse() function in SemanticKernelService
The GetResponse() function is the main entry point for our multi-agent application. Within that function, a variable named, messageHistory stores a list of historical messages from the chat session. The chatHistory object is used to construct this history and passed to the Semantic Kernel Chat Completion Agent object. The completionMessages list is used to store the response received from the agent which then needs to be persisted in Cosmos DB for the next iteration of the agent.

We're going to modify this function to provide that persistence with Cosmos DB.

In VS Code, return to the SemanticKernelService.cs in the /Services folder.
Navigate to the GetResponse() function.
Replace all of the code within the Try block with the code below:
csharp
            AgentFactory agentFactory = new AgentFactory();

            var agent = agentFactory.BuildAgent(_semanticKernel, _loggerFactory, bankService, tenantId, userId);

            ChatHistory chatHistory = new();

            // Load history
            foreach (var chatMessage in messageHistory)
            {
                if (chatMessage.SenderRole == "User")
                {
                    chatHistory.AddUserMessage(chatMessage.Text);
                }
                else
                {
                    chatHistory.AddAssistantMessage(chatMessage.Text);
                }
            }

            // Create an AgentThread using the ChatHistory object
            AgentThread agentThread = new ChatHistoryAgentThread(chatHistory);

            _promptDebugProperties = new List<LogProperty>();

            List<Message> completionMessages = new();
            List<DebugLog> completionMessagesLogs = new();


            await foreach (ChatMessageContent response in agent.InvokeAsync(userMessage.Text, agentThread))
            {
                string messageId = Guid.NewGuid().ToString();
                completionMessages.Add(new Message(userMessage.TenantId, userMessage.UserId, userMessage.SessionId, response.AuthorName ?? string.Empty, response.Role.ToString(), response.Content ?? string.Empty, messageId));
            }
            return new Tuple<List<Message>, List<DebugLog>>(completionMessages, completionMessagesLogs);
Update Chat Service
We can now update our Chat Service to store the messages generated between users and agents. In this step, we will add a new function that first calls the Cosmos DB service to get a Session object from our database. The Session object is part of an object hierarchy that defines the conversations between users and agents. A session has a name and also an array of messages for that conversation topic.

Let's view the data model for our chat session object.

In VS Code, navigate to the /Models/Chat folder.
Open the Session.cs class.
With a reference to the current session returned from the CosmosDBService, this function calls our newly implemented function to update the messages within the session object with any new or updated messages. Typically, this would include a single user prompt, followed by one or more responses from the agents.

In VS Code, navigate to the /Services folder and open the ChatService.cs class.
Paste the the below code as a new function within the class.
csharp
/// <summary>
/// Add user prompt and AI assistance response to the chat session message list object and insert into the data service as a transaction.
/// </summary>
private async Task AddPromptCompletionMessagesAsync(string tenantId, string userId, string sessionId, Message promptMessage, List<Message> completionMessages, List<DebugLog> completionMessageLogs)
{
    var session = await _cosmosDBService.GetSessionAsync(tenantId, userId, sessionId);

    completionMessages.Insert(0, promptMessage);
    await _cosmosDBService.UpsertSessionBatchAsync(completionMessages, completionMessageLogs, session);
}
Utilize and Store History in GetChatCompletionAsync
Next, locate the GetChatCompletionAsync() function.
Update the function by replacing the code within the Try block with the below:
csharp
            ArgumentNullException.ThrowIfNull(sessionId);

            // Retrieve conversation, including latest prompt.
            var archivedMessages = await _cosmosDBService.GetSessionMessagesAsync(tenantId, userId, sessionId);

            // Add both prompt and completion to cache, then persist in Cosmos DB
            var userMessage = new Message(tenantId,userId,sessionId, "User","User", userPrompt);

            // Generate the completion to return to the user
            var result = await _skService.GetResponse(userMessage, archivedMessages,_bankService,tenantId,userId);

            await AddPromptCompletionMessagesAsync(tenantId, userId,sessionId, userMessage, result.Item1, result.Item2);

            return result.Item1;
Activity 3: Test your Work
With the activities in this module complete, it is time to test your work.

Start the Backend
Return to the open terminal for the backend app in VS Code and type dotnet run
Start a Chat Session
We have a new agent now that thinks it works for a bank. So in our test here we are going to ask it banking-related questions.

Return to the frontend application in your browser.
Send the following message:
text
Can a senior citizen open a savings account?
Wait for the Agent response.
Send another message:
text
Does the interest rate vary?
Expected response: The Agent's response is contextually correct for the whole chat session.

You should see something like the output below.

Test output Module 2

Stop the Application
Return to VS Code.
Press Ctrl + C to stop the backend application.
Validation Checklist
Your implementation is successful if:

Your app compiles with no errors.
Your agent successfully responds with contextually correct information.
Module Solution
The following sections include the completed code for this Module. Copy and paste these into your project if you run into issues and cannot resolve.

Completed code for \Services\ChatService.cs
Completed code for \Services\SemanticKernelService.cs
Completed code for \Factories\AgentFactory.cs
Next Steps
Proceed to Module 3: Agent Specialization

Module 03 - Agent Specialization
Introduction
In this Module you'll learn how to implement agent specialization by creating Semantic Kernel Functions that provide the functionality necessary to power individual agents that comprise a multi-agent system.

Learning Objectives and Activities
Learn the basics for Semantic Kernel Agent Framework Functions
Learn how to implement semantic and natural language features using Vector indexing and search integration from Azure Cosmos DB.
Learn how to define tasks and communication protocols for seamless collaboration.
Module Exercises
Activity 1: Defining Bank Domain Data Models
Activity 2: Defining Agent Behavior
Activity 3: Integrating Bank Domain Functions as Plugins
Activity 4: Adding a Plugin to the Agent
Activity 5: Building an Agent Dynamically
Activity 6: Semantic Search
Activity 7: Test your Work
Activity 1: Defining Bank Domain Data Models
It is important to understand the need for agent specialization and have a basic grasp of how to build and integrate them. For the remainder of this module we will do just that for our banking scenario.

When working with any kind of data we need to review our data models.

In VS Code, navigate to the /Models/Banking folder.
Take a look at the names of the models here. These are the domain-specific functions for this bank we will create specialized agents for.
Activity 2: Defining Agent Behavior
Agent behavior is defined using prompts. These can be as simple as text in a string variable. However, it is often better to store these as external text files. In this solution we will use a format called, Prompty to manage our prompts.

Prompty is an asset class and file format designed to streamline the development and management of prompts for Large Language Models (LLMs). By combining configuration settings, sample data, and prompt templates into a single .prompty file, Prompty enhances observability, understandability, and portability for developers, thereby accelerating the prompt engineering process.

Understand Agent behavior using Prompty
In this activity we will review the existing Prompty files.

Common Agent Rules
In VS Code, navigate to the /Prompts folder.
Review the contents of CommonAgentRules.prompty.
The contents of this file doesn't define a single agent's behavior but provides a baseline for how all agents will behave. Think of it like a set of global rules for agents. All agents import the text from this prompt to govern their responses.

Coordinator Agent
Review the contents of Coordinator.prompty.
This agent is the coordinator for the entire multi-agent system we are building. Its purpose is to own the experience for users. It starts by greeting new users when they initiate a new session, then routes user requests to the correct agent(s) to handle on their behalf. Finally it asks for feedback on how it did its job.

Customer Support Agent
Review the contents of CustomerSupport.prompty.
This agent handles anything that appears to be a customer support request by a user. It can create, find and update services requests for users. It can also take certain action on behalf of users too.

Sales Agent
Review the contents of Sales.prompty.
This agent is used when customers ask questions about what kinds of services a bank offers. The data on the products the bank has are stored in Cosmos DB. This agent performs a vector search in Cosmos DB to find the most suitable products for a customer's request.

Transaction Agent
Review the contents of Transactions.prompty.
This agent handles any account-based transactions on behalf of the user including getting account balances, generating statements and doing fund transfers between accounts.

Retrieving the prompty text for Agents
In our banking solution we have four agents: transactions agent, sales agent, customer support agent, and a coordinator agent to manage all of them. With the behavior of the agents defined in Prompty, we now need to implement the code that will allow the application to load the agent behavior for each of the agents.

In VS Code, navigate to the /Models folder.
Review the contents of AgentTypes.cs.
Implementing the Agent Factory
We are now ready to complete the implementation for the Agent Factory created in the previous module. The AgentFactory will generate prompts based on the agentType parameter, allowing us to reuse the code and add more agents.

In VS Code, navigate to the /Factories folder.
Next, open the AgentFactory.cs class.
Next we need to replace our original hard-coded implementation from Module 2 to use the AgentType enum for our banking agents. It is also worth noting that it is here where the contents of the CommonAgentsRules.prompty are included as part of the system prompts that define our agents.

Replace the code for both GetAgentName() and GetAgentPrompts() with the code below:
Note: You will notice build errors for some of the updates you make during the activities in this module. These will be fixed in subsequent Activities.

csharp
        private string GetAgentName(AgentType agentType)
        {

            string name = string.Empty;
            switch (agentType)
            {
                case AgentType.Sales:
                    name = "Sales";
                    break;
                case AgentType.Transactions:
                    name = "Transactions";
                    break;
                case AgentType.CustomerSupport:
                    name = "CustomerSupport";
                    break;
                case AgentType.Coordinator:
                    name = "Coordinator";
                    break;
                default:
                    throw new ArgumentOutOfRangeException(nameof(agentType), agentType, null);
            }

            return name;
        }

        private string GetAgentPrompts(AgentType agentType)
        {

            string promptFile = string.Empty;
            switch (agentType)
            {
                case AgentType.Sales:
                    promptFile = "Sales.prompty";
                    break;
                case AgentType.Transactions:
                    promptFile = "Transactions.prompty";
                    break;
                case AgentType.CustomerSupport:
                    promptFile = "CustomerSupport.prompty";
                    break;
                case AgentType.Coordinator:
                    promptFile = "Coordinator.prompty";
                    break;
                default:
                    throw new ArgumentOutOfRangeException(nameof(agentType), agentType, null);
            }

            string prompt = $"{File.ReadAllText("Prompts/" + promptFile)}{File.ReadAllText("Prompts/CommonAgentRules.prompty")}";

            return prompt;
        }
Activity 3: Integrating Bank Domain Functions as Plugins
All banking domain code is encapsulated in a separate BankingDataService class. Let's add the banking domain functions to the agent plugins. For simplicity in this workshop, all functions reference BankingServices. However, kernel functions can be any managed code that enables the LLM to interact with the outside world. The Base plugin, inherited by all plugins, contains common code for all plugins. For best results the KernelFunction available in the agent plugin should be consistent with the agent system prompts.

To save time, the code for BasePlugin, SalesPlugin, and CustomerSupportPlugin are already implemented. The code for TransactionPlugin is left for you to implement.

In VS Code, navigate to the /AgentPlugins folder.
Open the TransactionPlugin.cs file.
Paste the following code into the class below the constructor.
csharp
    [KernelFunction]
    [Description("Adds a new Account Transaction request")]
    public async Task<ServiceRequest> AddFunTransferRequest(
        string debitAccountId,
        decimal amount,
        string requestAnnotation,
        string? recipientPhoneNumber = null,
        string? recipientEmailId = null)
    {
       _logger.LogTrace("Adding AccountTransaction request for User ID: {UserId}, Debit Account: {DebitAccountId}", _userId, debitAccountId);

       // Ensure non-null values for recipientEmailId and recipientPhoneNumber
       string emailId = recipientEmailId ?? string.Empty;
       string phoneNumber = recipientPhoneNumber ?? string.Empty;

       return await _bankService.CreateFundTransferRequestAsync(_tenantId, debitAccountId, _userId, requestAnnotation, emailId, phoneNumber, amount);
    }

    [KernelFunction]
    [Description("Get the transactions history between 2 dates")]
    public async Task<List<BankTransaction>> GetTransactionHistory(string accountId, DateTime startDate, DateTime endDate)
    {
       _logger.LogTrace("Fetching AccountTransaction history for Account: {AccountId}, From: {StartDate} To: {EndDate}", accountId, startDate, endDate);
       return await _bankService.GetTransactionsAsync(_tenantId, accountId, startDate, endDate);
    }
Activity 4: Adding a Plugin to the Agent
Similar to generating system prompts based on agent type, we need the plugins to be created dynamically. Next, we will implement a GetAgentKernel() function that dynamically generates a plugin based on the agent type.

In VS Code, navigate to the /Factories folder
Open the AgentFactory.cs class.
Paste the code below at the end of the class.
csharp
        private Kernel GetAgentKernel(Kernel kernel, AgentType agentType, ILoggerFactory loggerFactory, BankingDataService bankService, string tenantId, string userId)
        {
            Kernel agentKernel = kernel.Clone();
            switch (agentType)
            {
                case AgentType.Sales:
                    var salesPlugin = new SalesPlugin(loggerFactory.CreateLogger<SalesPlugin>(), bankService, tenantId, userId);
                    agentKernel.Plugins.AddFromObject(salesPlugin);
                    break;
                case AgentType.Transactions:
                    var transactionsPlugin = new TransactionPlugin(loggerFactory.CreateLogger<TransactionPlugin>(), bankService, tenantId, userId);
                    agentKernel.Plugins.AddFromObject(transactionsPlugin);
                    break;
                case AgentType.CustomerSupport:
                    var customerSupportPlugin = new CustomerSupportPlugin(loggerFactory.CreateLogger<CustomerSupportPlugin>(), bankService, tenantId, userId);
                    agentKernel.Plugins.AddFromObject(customerSupportPlugin);
                    break;
                case AgentType.Coordinator:
                    var CoordinatorPlugin = new CoordinatorPlugin(loggerFactory.CreateLogger<CoordinatorPlugin>(), bankService, tenantId, userId);
                    agentKernel.Plugins.AddFromObject(CoordinatorPlugin);
                    break;
                default:
                    throw new ArgumentException("Invalid plugin name");
            }

            return agentKernel;
        }
Activity 5: Building an Agent Dynamically
Now that we have dynamically generated Agent Prompt and Agent Kernel, we can make the agent build process dynamic based on the agentType parameter. Next, we will modify the BuildAgent() function within the AgentFactory class to dynamically add plugins to the agents.

Remain in the AgentFactory class.
Replace the BuildAgent() function with this code below.
csharp
        public ChatCompletionAgent BuildAgent(Kernel kernel, AgentType agentType, ILoggerFactory loggerFactory, BankingDataService bankService, string tenantId, string userId)
        {
            ChatCompletionAgent agent = new ChatCompletionAgent
            {
                Name = GetAgentName(agentType),
                Instructions = $"""{GetAgentPrompts(agentType)}""",
                Kernel = GetAgentKernel(kernel, agentType, loggerFactory, bankService, tenantId, userId),
                Arguments = new KernelArguments(new AzureOpenAIPromptExecutionSettings() { FunctionChoiceBehavior = FunctionChoiceBehavior.Auto() })
            };

            return agent;
        }
Activity 6: Semantic Search
The Sales Agent in this banking application performs a vector search in Cosmos DB to search for banking products and services for users. In this activity, you will learn how to configure vector indexing and search in Azure Cosmos DB and explore the container and vector indexing policies. Then learn how to implement vector search using for Semantic Kernel.

Create Data Model for Vector Search
Data Models used for Vector Search in Semantic Kernel need to be enhanced with additional attributes. We will use OfferTerm as vector search enabled data model.

In VS Code, navigate to the /Models/Banking folder.
Open the OfferTerm.cs class.
Paste this code within the class.
csharp
        [VectorStoreRecordKey]
        public required string Id { get; set; }

        [VectorStoreRecordData]
        public required string TenantId { get; set; }

        [VectorStoreRecordData]
        public required string OfferId { get; set; }

        [VectorStoreRecordData]
        public required string Name { get; set; }

        [VectorStoreRecordData]
        public required string Text { get; set; }

        [VectorStoreRecordData]
        public required string Type { get; set; }

        [VectorStoreRecordData]
        public required string AccountType { get; set; }

        [VectorStoreRecordVector(Dimensions: 1536, DistanceFunction: DistanceFunction.CosineSimilarity, IndexKind: IndexKind.QuantizedFlat)]
        public ReadOnlyMemory<float>? Vector { get; set; }
Update BankingDataService to include vector search
In VS Code, navigate to the /Services folder.
Open the the BankingDataService.cs file.
In the constructor of the class search for //To DO: Add vector search initialization code here.
Replace with the below code.
csharp
DefaultAzureCredential credential;
        if (string.IsNullOrEmpty(skSettings.AzureOpenAISettings.UserAssignedIdentityClientID))
        {
            credential = new DefaultAzureCredential();
        }
        else
        {
            credential = new DefaultAzureCredential(new DefaultAzureCredentialOptions
            {
                ManagedIdentityClientId = skSettings.AzureOpenAISettings.UserAssignedIdentityClientID
            });

        }

        _textEmbeddingGenerationService = new(
                deploymentName: skSettings.AzureOpenAISettings.EmbeddingsDeployment,
                endpoint: skSettings.AzureOpenAISettings.Endpoint,
                credential: credential);

        var jsonSerializerOptions = new JsonSerializerOptions { PropertyNamingPolicy = JsonNamingPolicy.CamelCase };
        var vectorStoreOptions = new AzureCosmosDBNoSQLVectorStoreRecordCollectionOptions<OfferTerm> { PartitionKeyPropertyName = "TenantId", JsonSerializerOptions = jsonSerializerOptions };
        _offerDataVectorStore = new AzureCosmosDBNoSQLVectorStoreRecordCollection<OfferTerm>(_database, _offerData.Id, vectorStoreOptions);
Within the same file, navigate below the constructor in which you just pasted the code above.
Then paste the following two functions.
csharp
        public async Task<List<OfferTerm>> SearchOfferTermsAsync(string tenantId, AccountType accountType, string requirementDescription)
        {
            try
            {
                // Generate Embedding
                ReadOnlyMemory<float> embedding = (await _textEmbeddingGenerationService.GenerateEmbeddingsAsync(
                       new[] { requirementDescription }
                   )).FirstOrDefault();


               string accountTypeString = accountType.ToString();

                // filters as LINQ expression
                Expression<Func<OfferTerm, bool>> linqFilter = term =>
                    term.TenantId == tenantId &&
                    term.Type == "Term" &&
                    term.AccountType == "Savings";

                var options = new VectorSearchOptions<OfferTerm>
                {
                    VectorProperty = term => term.Vector, // Correctly specify the vector property as a lambda expression
                    Filter = linqFilter, // Use the LINQ expression here
                    Top = 10,
                    IncludeVectors = false
                };


                var searchResults = await _offerDataVectorStore.VectorizedSearchAsync(embedding, options);

                List<OfferTerm> offerTerms = new();
                await foreach (var result in searchResults.Results)
                {
                    offerTerms.Add(result.Record);
                }
                return offerTerms;
            }
            catch (Exception ex)
            {
                _logger.LogError(ex.ToString());
                return new List<OfferTerm>();
            }
        }

        public async Task<Offer> GetOfferDetailsAsync(string tenantId, string offerId)
        {
            try
            {
                var partitionKey = new PartitionKey(tenantId);

                return await _offerData.ReadItemAsync<Offer>(
                       id: offerId,
                       partitionKey: new PartitionKey(tenantId));
            }
            catch (CosmosException ex)
            {
                _logger.LogError(ex.ToString());
                return null;
            }
        }
Next, we need to then connect the Sales Agent to our new functions.

In VS Code, navigate to the /AgentPlugins folder.
Open the SalesPlugin.cs file.
Navigate below the constructor.
Add these two functions to perform vector searches.
csharp
    [KernelFunction]
    [Description("Search offer terms of all available offers using vector search")]
    public async Task<List<OfferTerm>> SearchOfferTerms(AccountType accountType, string requirementDescription)
    {
        _logger.LogTrace($"Searching terms of all available offers matching '{requirementDescription}'");
        return await _bankService.SearchOfferTermsAsync(_tenantId, accountType, requirementDescription);
    }

    [KernelFunction]
    [Description("Get detail for an offer")]
    public async Task<Offer> GetOfferDetails(string offerId)
    {
        _logger.LogTrace($"Fetching Offer");
        return await _bankService.GetOfferDetailsAsync(_tenantId, offerId);
    }
Select the Agent to get response
In VS Code, navigate to the /Services folder.
Open the SemanticKernelService.cs file.
Locate the GetResponse() function.
Locate this line of code, var agent = agentFactory.BuildAgent(_semanticKernel, _loggerFactory, bankService, tenantId, userId);
It should be easy to spot as .BuildAgent should have a red squiggly line below it.
Replace it with the line of code below.
c#
var agent = agentFactory.BuildAgent(_semanticKernel, AgentType.Sales, _loggerFactory, bankService, tenantId, userId);
Activity 7: Test your Work
With the activities in this module complete, it is time to test your work.

Start the Backend
Return to the open terminal for the backend app in VS Code and type dotnet run
Start a Chat Session
Return to the frontend application in your browser.
Send a message to test the current Sales AgentType.
View the response in the frontend.
text
I'm looking for a high interest savings account
Return to VS Code.
Notice the output in the terminal showing the action taken by the Sales Agent to your prompt.
Stop the Application
Within the backend terminal, press Ctrl + C to stop the backend application.
Validation Checklist
Each Agent response is per the corresponding prompty file contents and the plugin functions.
Semantic Search functions correctly
Module Solution
The following sections include the completed code for this Module. Copy and paste these into your project if you run into issues and cannot resolve.

Completed code for \Services\SemanticKernelService.cs
Completed code for \Factories\AgentFactory.cs
Completed code for \AgentPlugins\TransactionPlugin.cs
Completed code for \AgentPlugins\SalesPlugin.cs
Completed code for \Models\Banking\OfferTerm.cs
Completed code for \Services\BankingDataService.cs
Next Steps
Proceed to Module 4 - Multi-Agent Orchestration

Module 04 - Multi-Agent Orchestration
Introduction
In this Module you'll learn how to implement the multi-agent orchestration to tie all of the agents you have created so far together into a single system. You'll also learn how to test the system as a whole is working correctly and how to debug and monitor the agents performance and behavior and troubleshoot them.

Learning Objectives
Learn how to write prompts for agents
Define agent routing
Learn how to define API contracts for a multi-agent system
Learn how to test and debug agents, monitoring
Module Exercises
Activity 1: Define Agents and Roles
Optional Activity 2: Implement Agent Tracing and Monitoring
Activity 3: Test your Work
Activity 1: Define Agents and Roles
When dealing with multiple agents, clear agent roles is important to avoid conflicts and making sure customer gets the most appropriate response.

Add Selection Strategy for Agent Selection
SelectionStrategy is the mechanism in SemanticKernel that determines the next participant. By using the SelectionStrategy, we can identify the available agents and guide the LLM by defining the selection rule in natural language.

In VS Code, navigate to the /Prompts folder
Review the contents of SelectionStrategy.prompty
text
Examine RESPONSE and choose the next participant.

Choose only from these participants:
- Coordinator
- CustomerSupport
- Sales
- Transactions

Always follow these rules when choosing the next participant:
- Determine the nature of the user's request and route it to the appropriate agent
- If the user is responding to an agent, select that same agent.
- If the agent is responding after fetching or verifying data , select that same agent.
- If unclear, select Coordinator.
Add Termination Strategy for Agent response
Similar to how SelectionStrategy selects an agent, TerminationStrategy decides when agents should stop responding. This is crucial to prevent multiple unwanted agent chatter in response to a user prompt. TerminationStrategy is the mechanism in SemanticKernel that determines when to stop. It is defined in natural language and instructs the LLM to return YES if more agent participation is required, otherwise it should return NO.

In VS Code, navigate to the /Prompts folder.
Review the contents of TerminationStrategy.prompty
text
Determine if agent has requested user input or has responded to the user's query.
Respond with the word NO (without explanation) if agent has requested user input.
Otherwise, respond with the word YES (without explanation) if any the following conditions are met:
- An action is pending by an agent.
- Further participation from an agent is required
- The information requested by the user was not provided by the current agent.
ChatResponseFormat
By default, the LLM responds to user prompts in natural language. However, we can enforce a structured format in its responses. A structured format allows us to parse the response and utilize it in our code for decision-making.

Lets define the models for the response.

ContinuationInfo
In VS Code, navigate to the /Models/ChatInfoFormats folder.
Review the contents of ContinuationInfo.cs.
c#
namespace MultiAgentCopilot.Models.ChatInfoFormats
{
    public class ContinuationInfo
    {
        public string AgentName { get; set; } = string.Empty;
        public string Reason { get; set; } = string.Empty;
    }
}
TerminationInfo
Remain in the same ChatInfoFormats folder.
Review the contents of TerminationInfo.cs
csharp
namespace MultiAgentCopilot.Models.ChatInfoFormats
{
    internal class TerminationInfo
    {
        public bool ShouldContinue { get; set; }
        public string Reason { get; set; } = string.Empty;
    }
}
Let's define a format builder that the LLM can use to output the Continuation and Termination models as responses.

In VS Code, navigate to the /StructuredFormats folder.
Review the contents of ChatResponseFormat.cs.
csharp
namespace MultiAgentCopilot.StructuredFormats
{
    internal static class ChatResponseFormatBuilder
    {
        internal enum ChatResponseStrategy
        {
            Continuation,
            Termination

        }

        internal static string BuildFormat(ChatResponseStrategy strategyType)
        {
            switch (strategyType)
            {
                case ChatResponseStrategy.Continuation:
                    string jsonSchemaFormat_Continuation = """
                    {
                        "type": "object", 
                            "properties": {
                                "AgentName": { "type": "string", "description":"name of the selected agent" },
                                "Reason": { "type": "string","description":"reason for selecting the agent" }
                            },
                            "required": ["AgentName", "Reason"],
                            "additionalProperties": false
                    }
                    """;

                    return jsonSchemaFormat_Continuation;
                case ChatResponseStrategy.Termination:
                    string jsonSchemaFormat_termination = """
                    {
                        "type": "object", 
                            "properties": {
                                "ShouldContinue": { "type": "boolean", "description":"Does conversation require further agent participation" },
                                "Reason": { "type": "string","description":"List the conditions that evaluated to true for further agent participation" }
                            },
                            "required": ["ShouldContinue", "Reason"],
                            "additionalProperties": false
                    }
                    """;

                    return jsonSchemaFormat_termination;
                default:
                    return "";
            }
        }
    }
}
StrategyPrompts
Just like Agent System Prompts lets return StrategyPrompts based on strategyType.

In VS Code, navigate to the /Factories folder.
Open the AgentFactory.cs.
Navigate to the bottom of the file and locate the end of the GetAgentKernel() function.
Add the following code as five new functions to the bottom of the class.
csharp
       public delegate void LogCallback(string key, string value);

       public static string GetStrategyPrompts(ChatResponseStrategy strategyType)
       {
          string prompt = string.Empty;
          switch (strategyType)
          {
                case ChatResponseStrategy.Continuation:
                   prompt = File.ReadAllText("Prompts/SelectionStrategy.prompty");
                   break;
                case ChatResponseStrategy.Termination:
                   prompt = File.ReadAllText("Prompts/TerminationStrategy.prompty");
                   break;
          }
          return prompt;
       }

       public AgentGroupChat BuildAgentGroupChat(Kernel kernel, ILoggerFactory loggerFactory, LogCallback logCallback, BankingDataService bankService, string tenantId, string userId)
        {
            AgentGroupChat agentGroupChat = new AgentGroupChat();
            var chatModel = kernel.GetRequiredService<IChatCompletionService>();

            //kernel.AutoFunctionInvocationFilters.Add(new AutoFunctionInvocationLoggingFilter(loggerFactory.CreateLogger<AutoFunctionInvocationLoggingFilter>()));

            foreach (AgentType agentType in Enum.GetValues(typeof(AgentType)))
            {
                agentGroupChat.AddAgent(BuildAgent(kernel, agentType, loggerFactory, bankService, tenantId, userId));
            }

            agentGroupChat.ExecutionSettings = GetAgentGroupChatSettings(kernel, logCallback);


            return agentGroupChat;
        }

        private OpenAIPromptExecutionSettings GetExecutionSettings(ChatResponseFormatBuilder.ChatResponseStrategy strategyType)
        {
            ChatResponseFormat infoFormat;
            infoFormat = ChatResponseFormat.CreateJsonSchemaFormat(
            jsonSchemaFormatName: $"agent_result_{strategyType.ToString()}",
            jsonSchema: BinaryData.FromString($"""
                {ChatResponseFormatBuilder.BuildFormat(strategyType)}
                """));
            var executionSettings = new OpenAIPromptExecutionSettings
            {
                ResponseFormat = infoFormat
            };

            return executionSettings;
        }

        private KernelFunction GetStrategyFunction(ChatResponseFormatBuilder.ChatResponseStrategy strategyType)
        {

            KernelFunction function =
                AgentGroupChat.CreatePromptFunctionForStrategy(
                    $$$"""
                    {{{GetStrategyPrompts(strategyType)}}}

                    RESPONSE:
                    {{$lastmessage}}
                    """,
                    safeParameterNames: "lastmessage");

            return function;
        }

        private AgentGroupChatSettings GetAgentGroupChatSettings(Kernel kernel, LogCallback logCallback)
        {
            ChatHistoryTruncationReducer historyReducer = new(5);

            AgentGroupChatSettings ExecutionSettings = new AgentGroupChatSettings
            {
                SelectionStrategy =
                    new KernelFunctionSelectionStrategy(GetStrategyFunction(ChatResponseFormatBuilder.ChatResponseStrategy.Continuation), kernel)
                    {
                        Arguments = new KernelArguments(GetExecutionSettings(ChatResponseFormatBuilder.ChatResponseStrategy.Continuation)),
                        // Save tokens by only including the final few responses
                        HistoryReducer = historyReducer,
                        // The prompt variable name for the history argument.
                        HistoryVariableName = "lastmessage",
                        // Returns the entire result value as a string.
                        ResultParser = (result) =>
                        {
                            var resultString = result.GetValue<string>();
                            if (!string.IsNullOrEmpty(resultString))
                            {
                                var ContinuationInfo = JsonSerializer.Deserialize<ContinuationInfo>(resultString);
                                //logCallback("SELECTION - Agent", ContinuationInfo!.AgentName); 
                                //logCallback("SELECTION - Reason", ContinuationInfo!.Reason);                       
                                return ContinuationInfo!.AgentName;
                            }
                            else
                            {
                                return string.Empty;
                            }
                        }
                    },
                TerminationStrategy =
                    new KernelFunctionTerminationStrategy(GetStrategyFunction(ChatResponseFormatBuilder.ChatResponseStrategy.Termination), kernel)
                    {
                        Arguments = new KernelArguments(GetExecutionSettings(ChatResponseFormatBuilder.ChatResponseStrategy.Termination)),
                        // Save tokens by only including the final response
                        HistoryReducer = historyReducer,
                        // The prompt variable name for the history argument.
                        HistoryVariableName = "lastmessage",
                        // Limit total number of turns
                        MaximumIterations = 8,
                        // user result parser to determine if the response is "yes"
                        ResultParser = (result) =>
                        {
                            var resultString = result.GetValue<string>();
                            if (!string.IsNullOrEmpty(resultString))
                            {
                                var terminationInfo = JsonSerializer.Deserialize<TerminationInfo>(resultString);
                                //logCallback("TERMINATION - Continue", terminationInfo!.ShouldContinue.ToString()); 
                                //logCallback("TERMINATION - Reason", terminationInfo!.Reason); 
                                return !terminationInfo!.ShouldContinue;
                            }
                            else
                            {
                                return false;
                            }
                        }
                    },
            };

            return ExecutionSettings;
        }
Replace Agent with AgentGroupChat in SemanticKernel
Until now the responses we received were from a single agent, lets use AgentGroupChat to orchestrate a chat where multiple agents participate.

In VS Code, navigate to Services/SemanticKernelService.cs
Locate the GetResponse() function.
Add the below code after the GetResponse() function.
csharp
    private void LogMessage(string key, string value)
    {
        _promptDebugProperties.Add(new LogProperty(key, value));
    }
Next, update the the GetResponse() function. Inside, the Try block, replace with the code below:
csharp
            AgentFactory agentFactory = new AgentFactory();

            var agentGroupChat = agentFactory.BuildAgentGroupChat(_semanticKernel, _loggerFactory, LogMessage, bankService, tenantId, userId);

            // Load history
            foreach (var chatMessage in messageHistory)
            {
                AuthorRole? role = AuthorRoleHelper.FromString(chatMessage.SenderRole);
                var chatMessageContent = new ChatMessageContent
                {
                    Role = role ?? AuthorRole.User,
                    Content = chatMessage.Text
                };
                agentGroupChat.AddChatMessage(chatMessageContent);
            }

            _promptDebugProperties = new List<LogProperty>();

            List<Message> completionMessages = new();
            List<DebugLog> completionMessagesLogs = new();
            do
            {
                var userResponse = new ChatMessageContent(AuthorRole.User, userMessage.Text);
                agentGroupChat.AddChatMessage(userResponse);

                agentGroupChat.IsComplete = false;

                await foreach (ChatMessageContent response in agentGroupChat.InvokeAsync())
                {
                    string messageId = Guid.NewGuid().ToString();
                    string debugLogId = Guid.NewGuid().ToString();
                    completionMessages.Add(new Message(userMessage.TenantId, userMessage.UserId, userMessage.SessionId, response.AuthorName ?? string.Empty, response.Role.ToString(), response.Content ?? string.Empty, messageId, debugLogId));

                    // TO DO : Add DebugLog code here

                }
            }
            while (!agentGroupChat.IsComplete);


            return new Tuple<List<Message>, List<DebugLog>>(completionMessages, completionMessagesLogs);
Activity 2: Implement Agent Tracing and Monitoring
Note: This activity is optional. If you are running short on time during this lab, skip to Activity 3: Test your work.

In this activity, you will learn how to define an API service layer for a multi-agent backend and learn how to configure tracing and monitoring to enable testing and debugging for agents.

You may have noticed when chatting with the agents you are unable to see which functions are invoked and why the LLM selects an agent. Lets add some code to bring visibility to behind the scene decision making process.

Log the kernel function selection
To log the data used by the LLM to invoke functions, we will create a class named AutoFunctionInvocationLoggingFilter.

In VS Code, navigate to LogFilter folder.
Review the contents of AutoFunctionInvocationLoggingFilter.cs.
c#
using Microsoft.SemanticKernel;
using System.Text.Json;

namespace MultiAgentCopilot.Logs
{
    public sealed class AutoFunctionInvocationLoggingFilter : IAutoFunctionInvocationFilter
    {
        private readonly ILogger<AutoFunctionInvocationLoggingFilter> _logger;

        public AutoFunctionInvocationLoggingFilter(ILogger<AutoFunctionInvocationLoggingFilter> logger)
        {
            _logger = logger;
        }

        public async Task OnAutoFunctionInvocationAsync(AutoFunctionInvocationContext context, Func<AutoFunctionInvocationContext, Task> next)
        {
            var functionCalls = FunctionCallContent.GetFunctionCalls(context.ChatHistory.Last()).ToList();

            if (_logger.IsEnabled(LogLevel.Trace))
            {
                functionCalls.ForEach(functionCall
                    => _logger.LogTrace(
                        "Function call requests: {PluginName}-{FunctionName}({Arguments})",
                        functionCall.PluginName,
                        functionCall.FunctionName,
                        JsonSerializer.Serialize(functionCall.Arguments)));
            }

            await next(context);
        }
    }
}
Update Semantic Kernel's AutoFunctionInvocationFilters
In VS Code, navigate to the AgentFactory.cs class.
Uncomment the following line in the BuildAgentGroupChat() function.
csharp
    //kernel.AutoFunctionInvocationFilters.Add(new AutoFunctionInvocationLoggingFilter(loggerFactory.CreateLogger<AutoFunctionInvocationLoggingFilter>()));
Logging the Termination and selection Strategy
Search for \logCallback inside GetAgentGroupChatSettings() function.
Uncomment it in 4 places it appears.
Store the log information along with the chat response
Now that we have log information for AgentSelection and Termination, we also need to persist these logs for later retrieval. Storing these DebugLogs in the ChatData container of Cosmos DB along with the other chat data will help us view the logs in the context of the conversation.

In VS Code, navigate to Services/SemanticKernelService.cs.
Locate the GetResponse() function.
Search for // TO DO : Add DebugLog code here
Add the code below:
csharp
    if (_promptDebugProperties.Count > 0)
    {
        var completionMessagesLog = new DebugLog(userMessage.TenantId, userMessage.UserId, userMessage.SessionId, messageId, debugLogId);
        completionMessagesLog.PropertyBag = _promptDebugProperties;
        completionMessagesLogs.Add(completionMessagesLog);
    }
Activity 3: Test your Work
In the previous module we tested each agent independently. With the code changes in this module we should now be able to orchestrate a multi-agent chat where agent selection is automated based on the SelectionStrategy and agent prompts. Lets go ahead and test if the code works as expected.

Start the Backend
Return to the open terminal for the backend app in VS Code and type dotnet run
Start a Chat Session
For each response in our testing below, click on the Bug icon to see the Debug log to understand the agent selection and termination strategy. Debug Log

Return to the frontend application in your browser.
Start a new conversation.
Try the below prompts. Provide more infomration if prompted.
Who can help me here?
Transfer $50 to my friend.
When prompted for account and email, enter, "Account is Acc001 and Email is Sandeep@contoso.com"
Looking for a Savings account with high interest rate.
File a complaint about theft from my account.
When prompted confirm its the same account or enter a new account (Acc001 to Acc009) and provide any details it asks for.
How much did I spend on groceries? (If prompted, say over the last 6 months)
Provide me a statement of my account. (If prompted, give it an account number ranging from Acc001 to Acc009)
Stop the Application
In the backend terminal, press Ctrl + C to stop the application.
Validation Checklist
Depending on the user prompt the agent selection is dynamic.
All the agents context of the previous messages in teh conversation.
The agents are able to invoke the right plugin function to interact with BankingService.
Vector search works as expected.
Common Issues and Solutions
Multiple agents respond together or Wrong agent responding:

View the 'DebugLog' by using the Bug icon in each impacted AI response.
Study the Termination Reason
Edit the appropriate Prompty files to resolve the conflict.
Agent response are invalid:

Change in model and/or its version can cause invalid/irrelevant agent behavior.
Thorough testing with updated prompts will be required.
Module Solution
The following sections include the completed code for this Module. Copy and paste these into your project if you run into issues and cannot resolve.

Completed code for \Services\SemanticKernelService.cs
Completed code for \Factories\AgentFactory.cs
Next Steps
Congratulations!!! You have completed this hands-on-lab!!!

You can see the full source code for this lab for both Semantic Kernel and LangGraph at https://github.com/AzureCosmosDB/banking-multi-agent-workshop/. You can also take this lab again or the LangGraph one at https://github.com/AzureCosmosDB/banking-multi-agent-workshop/tree/hol. We hope you enjoyed this lab.

